{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "K_HmA7-_yqcP",
        "outputId": "a9019a4d-8a20-42bb-91ab-850b67aab948"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>review_es</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Probablemente mi película favorita de todos lo...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Seguro que me gustaría ver una resurrección de...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Este espectáculo fue una idea increíble, fresc...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Alentados por los comentarios positivos sobre ...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Si te gusta la risa original desgarradora, te ...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                          review_es sentimiento\n",
              "0   0  Uno de los otros críticos ha mencionado que de...    positivo\n",
              "1   1  Una pequeña pequeña producción.La técnica de f...    positivo\n",
              "2   2  Pensé que esta era una manera maravillosa de p...    positivo\n",
              "3   3  Básicamente, hay una familia donde un niño peq...    negativo\n",
              "4   4  El \"amor en el tiempo\" de Petter Mattei es una...    positivo\n",
              "5   5  Probablemente mi película favorita de todos lo...    positivo\n",
              "6   6  Seguro que me gustaría ver una resurrección de...    positivo\n",
              "7   7  Este espectáculo fue una idea increíble, fresc...    negativo\n",
              "8   8  Alentados por los comentarios positivos sobre ...    negativo\n",
              "9   9  Si te gusta la risa original desgarradora, te ...    positivo"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_criticas = pd.read_csv(\"./train.csv\",encoding='utf-8')\n",
        "df = df_criticas.copy()\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "AI14cg7RU2O3",
        "outputId": "7010b773-b3e2-4856-d631-0485fa1d29da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Porcentaje en sentimiento')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_porcentaje = df['sentimiento'].value_counts(normalize=True)*100\n",
        "\n",
        "df_porcentaje.plot(kind='bar',color=[(0,1,0),(1,0,0)])\n",
        "plt.ylabel(\"Porcentaje de criticas\")\n",
        "plt.xlabel(\"Sentimiento\")\n",
        "plt.title(\"Porcentaje en sentimiento\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "NMAEQpL104AW",
        "outputId": "0a2a95dd-184a-490d-c5ed-0a08ebf5663e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['num_palabras'] = df['review_es'].str.split().apply(len)\n",
        "plt.scatter(df['sentimiento'], df['num_palabras'])\n",
        "plt.xlabel('Cantidad de palabras')\n",
        "plt.ylabel('Sentimiento')\n",
        "plt.title('La cantidad de palabras en relacion al sentimiento')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yth1cZjrPWR",
        "outputId": "5a94cf97-fc7a-4fd0-dd28-ffc7c4a2d6e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['actores' 'actuación' 'ahora' 'al' 'algo' 'alguien' 'algunas' 'algunos'\n",
            " 'antes' 'aquí' 'así' 'aunque' 'años' 'aún' 'bastante' 'bien' 'buen'\n",
            " 'buena' 'bueno' 'cada' 'casi' 'cine' 'como' 'con' 'cosas' 'creo'\n",
            " 'cualquier' 'cuando' 'cómo' 'debe' 'decir' 'del' 'demasiado' 'desde'\n",
            " 'después' 'director' 'donde' 'dos' 'durante' 'e' 'ella' 'ellos' 'embargo'\n",
            " 'entonces' 'entre' 'era' 'esa' 'escena' 'escenas' 'ese' 'eso' 'estaba'\n",
            " 'este' 'esto' 'estoy' 'está' 'están' 'final' 'forma' 'fue' 'fuera' 'gran'\n",
            " 'ha' 'haber' 'había' 'hace' 'hacer' 'han' 'hasta' 'hay' 'he' 'hecho'\n",
            " 'historia' 'hizo' 'hombre' 'incluso' 'le' 'luego' 'lugar' 'mal' 'manera'\n",
            " 'mayoría' 'me' 'mejor' 'mejores' 'menos' 'mi' 'mientras' 'minutos'\n",
            " 'mismo' 'momento' 'muchas' 'mucho' 'muchos' 'muy' 'más' 'nada' 'ni'\n",
            " 'nunca' 'o' 'otra' 'otro' 'otros' 'parece' 'parte' 'películas' 'pero'\n",
            " 'personaje' 'personajes' 'personas' 'poco' 'podría' 'porque' 'primera'\n",
            " 'puede' 'puedo' 'qué' 'real' 'realidad' 'realmente' 'sea' 'ser' 'si'\n",
            " 'sido' 'siempre' 'simplemente' 'sin' 'sobre' 'solo' 'son' 'su' 'sus' 'sí'\n",
            " 'tal' 'también' 'tan' 'tanto' 'te' 'tener' 'tenía' 'tiempo' 'tiene'\n",
            " 'tipo' 'toda' 'todas' 'todo' 'todos' 'trabajo' 'trama' 'través' 'uno'\n",
            " 'veces' 'ver' 'vez' 'vi' 'vida' 'visto' 'ya' 'él']\n",
            "159\n",
            "[[0 0 0 ... 1 2 1]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 2 0]\n",
            " [0 0 1 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "vectorizer = CountVectorizer(min_df=0.1, max_df=0.7,token_pattern=r'\\b(?:[^\\d\\W_])+\\b')\n",
        "X = vectorizer.fit_transform(df['review_es'])\n",
        "palabras = vectorizer.get_feature_names_out()\n",
        "print(palabras)\n",
        "print(len(palabras))\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EG2BhvE8FTPy",
        "outputId": "d3a3dcef-ef6b-45eb-b80b-a7bafe7ea9ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n",
            "C:\\Users\\LUCAS\\AppData\\Local\\Temp\\ipykernel_1032\\2652835665.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[palabra] = X.toarray()[:, i]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>review_es</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>num_palabras</th>\n",
              "      <th>actores</th>\n",
              "      <th>actuación</th>\n",
              "      <th>ahora</th>\n",
              "      <th>al</th>\n",
              "      <th>algo</th>\n",
              "      <th>alguien</th>\n",
              "      <th>...</th>\n",
              "      <th>través</th>\n",
              "      <th>uno</th>\n",
              "      <th>veces</th>\n",
              "      <th>ver</th>\n",
              "      <th>vez</th>\n",
              "      <th>vi</th>\n",
              "      <th>vida</th>\n",
              "      <th>visto</th>\n",
              "      <th>ya</th>\n",
              "      <th>él</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>161</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>137</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Probablemente mi película favorita de todos lo...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Seguro que me gustaría ver una resurrección de...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Este espectáculo fue una idea increíble, fresc...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Alentados por los comentarios positivos sobre ...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Si te gusta la risa original desgarradora, te ...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                          review_es sentimiento   \n",
              "0   0  Uno de los otros críticos ha mencionado que de...    positivo  \\\n",
              "1   1  Una pequeña pequeña producción.La técnica de f...    positivo   \n",
              "2   2  Pensé que esta era una manera maravillosa de p...    positivo   \n",
              "3   3  Básicamente, hay una familia donde un niño peq...    negativo   \n",
              "4   4  El \"amor en el tiempo\" de Petter Mattei es una...    positivo   \n",
              "5   5  Probablemente mi película favorita de todos lo...    positivo   \n",
              "6   6  Seguro que me gustaría ver una resurrección de...    positivo   \n",
              "7   7  Este espectáculo fue una idea increíble, fresc...    negativo   \n",
              "8   8  Alentados por los comentarios positivos sobre ...    negativo   \n",
              "9   9  Si te gusta la risa original desgarradora, te ...    positivo   \n",
              "\n",
              "   num_palabras  actores  actuación  ahora  al  algo  alguien  ...  través   \n",
              "0           345        0          0      0   2     0        0  ...       0  \\\n",
              "1           161        1          0      0   0     0        0  ...       0   \n",
              "2           173        0          0      0   1     0        0  ...       0   \n",
              "3           137        0          0      0   1     0        0  ...       0   \n",
              "4           237        0          1      0   0     0        0  ...       0   \n",
              "5           123        0          0      0   0     0        0  ...       0   \n",
              "6           157        0          0      0   0     0        0  ...       0   \n",
              "7           168        0          0      1   0     0        0  ...       0   \n",
              "8           120        0          1      0   1     0        0  ...       0   \n",
              "9            31        0          0      0   0     0        0  ...       0   \n",
              "\n",
              "   uno  veces  ver  vez  vi  vida  visto  ya  él  \n",
              "0    1      0    1    0   0     0      1   2   1  \n",
              "1    1      2    1    0   0     1      0   0   0  \n",
              "2    0      0    1    0   0     0      0   0   0  \n",
              "3    0      0    1    0   1     1      0   0   0  \n",
              "4    2      0    2    0   0     1      0   1   0  \n",
              "5    1      1    1    0   0     0      1   0   0  \n",
              "6    0      0    2    0   0     0      0   0   0  \n",
              "7    0      0    0    1   0     0      0   1   0  \n",
              "8    2      1    2    1   0     0      1   0   0  \n",
              "9    0      0    0    0   0     0      0   0   0  \n",
              "\n",
              "[10 rows x 163 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i, palabra in enumerate(palabras):\n",
        "    df[palabra] = X.toarray()[:, i]\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0fPrR2pLGjbm"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cQ-pFNgqGuEW"
      },
      "outputs": [],
      "source": [
        "df.drop(columns='ID',inplace=True)\n",
        "df.drop(columns='review_es',inplace=True)\n",
        "\n",
        "ds_x=df.drop(['sentimiento'], axis='columns', inplace=False)\n",
        "ds_y = df['sentimiento'].copy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(ds_x,\n",
        "                                                    ds_y,\n",
        "                                                    test_size=0.3,  #proporcion 70/30\n",
        "                                                    random_state=4, #semilla\n",
        "                                                    stratify=df[\"sentimiento\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l5PNIkseJKDK",
        "outputId": "19f6208e-5b18-44a0-c296-0596e63764f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['negativo', 'positivo']\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\LUCAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={&#x27;max_depth&#x27;: [20, 21, 22, 23, 24, 25,\n",
              "                                                      26, 27, 28, 29, 30, 31,\n",
              "                                                      32, 33, 34, 35, 36, 37,\n",
              "                                                      38, 39, 40, 41, 42, 43,\n",
              "                                                      44, 45, 46, 47, 48, 49, ...],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [20, 21, 22, 23, 24,\n",
              "                                                             25, 26, 27, 28, 29,\n",
              "                                                             30, 31, 32, 33, 34,\n",
              "                                                             35, 36, 37, 38, 39,\n",
              "                                                             40, 41, 42, 43, 44,\n",
              "                                                             45, 46, 47, 48, 49, ...],\n",
              "                                        &#x27;min_samples_split&#x27;: [20, 21, 22, 23,\n",
              "                                                              24, 25, 26, 27,\n",
              "                                                              28, 29, 30, 31,\n",
              "                                                              32, 33, 34, 35,\n",
              "                                                              36, 37, 38, 39,\n",
              "                                                              40, 41, 42, 43,\n",
              "                                                              44, 45, 46, 47,\n",
              "                                                              48, 49, ...],\n",
              "                                        &#x27;n_estimators&#x27;: [200, 201, 202, 203,\n",
              "                                                         204, 205, 206, 207,\n",
              "                                                         208, 209, 210, 211,\n",
              "                                                         212, 213, 214, 215,\n",
              "                                                         216, 217, 218, 219,\n",
              "                                                         220, 221, 222, 223,\n",
              "                                                         224, 225, 226, 227,\n",
              "                                                         228, 229, ...]},\n",
              "                   random_state=42, scoring=make_scorer(f1_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={&#x27;max_depth&#x27;: [20, 21, 22, 23, 24, 25,\n",
              "                                                      26, 27, 28, 29, 30, 31,\n",
              "                                                      32, 33, 34, 35, 36, 37,\n",
              "                                                      38, 39, 40, 41, 42, 43,\n",
              "                                                      44, 45, 46, 47, 48, 49, ...],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [20, 21, 22, 23, 24,\n",
              "                                                             25, 26, 27, 28, 29,\n",
              "                                                             30, 31, 32, 33, 34,\n",
              "                                                             35, 36, 37, 38, 39,\n",
              "                                                             40, 41, 42, 43, 44,\n",
              "                                                             45, 46, 47, 48, 49, ...],\n",
              "                                        &#x27;min_samples_split&#x27;: [20, 21, 22, 23,\n",
              "                                                              24, 25, 26, 27,\n",
              "                                                              28, 29, 30, 31,\n",
              "                                                              32, 33, 34, 35,\n",
              "                                                              36, 37, 38, 39,\n",
              "                                                              40, 41, 42, 43,\n",
              "                                                              44, 45, 46, 47,\n",
              "                                                              48, 49, ...],\n",
              "                                        &#x27;n_estimators&#x27;: [200, 201, 202, 203,\n",
              "                                                         204, 205, 206, 207,\n",
              "                                                         208, 209, 210, 211,\n",
              "                                                         212, 213, 214, 215,\n",
              "                                                         216, 217, 218, 219,\n",
              "                                                         220, 221, 222, 223,\n",
              "                                                         224, 225, 226, 227,\n",
              "                                                         228, 229, ...]},\n",
              "                   random_state=42, scoring=make_scorer(f1_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={'max_depth': [20, 21, 22, 23, 24, 25,\n",
              "                                                      26, 27, 28, 29, 30, 31,\n",
              "                                                      32, 33, 34, 35, 36, 37,\n",
              "                                                      38, 39, 40, 41, 42, 43,\n",
              "                                                      44, 45, 46, 47, 48, 49, ...],\n",
              "                                        'min_samples_leaf': [20, 21, 22, 23, 24,\n",
              "                                                             25, 26, 27, 28, 29,\n",
              "                                                             30, 31, 32, 33, 34,\n",
              "                                                             35, 36, 37, 38, 39,\n",
              "                                                             40, 41, 42, 43, 44,\n",
              "                                                             45, 46, 47, 48, 49, ...],\n",
              "                                        'min_samples_split': [20, 21, 22, 23,\n",
              "                                                              24, 25, 26, 27,\n",
              "                                                              28, 29, 30, 31,\n",
              "                                                              32, 33, 34, 35,\n",
              "                                                              36, 37, 38, 39,\n",
              "                                                              40, 41, 42, 43,\n",
              "                                                              44, 45, 46, 47,\n",
              "                                                              48, 49, ...],\n",
              "                                        'n_estimators': [200, 201, 202, 203,\n",
              "                                                         204, 205, 206, 207,\n",
              "                                                         208, 209, 210, 211,\n",
              "                                                         212, 213, 214, 215,\n",
              "                                                         216, 217, 218, 219,\n",
              "                                                         220, 221, 222, 223,\n",
              "                                                         224, 225, 226, 227,\n",
              "                                                         228, 229, ...]},\n",
              "                   random_state=42, scoring=make_scorer(f1_score))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "param_dist = {\n",
        "    'n_estimators': list(range(200,500)),\n",
        "    'max_depth': list(range(20, 100)),\n",
        "    'min_samples_split': list(range(20, 100)),\n",
        "    'min_samples_leaf': list(range(20, 100))\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring= make_scorer(f1_score),\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(x_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tNT1fc1jEfK",
        "outputId": "8c7325cb-e0a1-4056-fe22-c1d79487a8bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 336,\n",
              " 'min_samples_split': 83,\n",
              " 'min_samples_leaf': 64,\n",
              " 'max_depth': 49}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "uMCgcTQWaalO",
        "outputId": "664d5e95-f747-47b5-f28e-380bbf434db1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=49, min_samples_leaf=64, min_samples_split=83,\n",
              "                       n_estimators=336)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=49, min_samples_leaf=64, min_samples_split=83,\n",
              "                       n_estimators=336)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=49, min_samples_leaf=64, min_samples_split=83,\n",
              "                       n_estimators=336)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_forest =  rf.set_params(**random_search.best_params_)\n",
        "random_forest.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "bnNDs2o2grAe",
        "outputId": "a7b8a424-924b-492f-cf99-f4940cfd1787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7063790487499175\n",
            "Accuracy Score: 0.7032666666666667\n",
            "Recall Score: 0.7138666666666666\n",
            "Precision Score: 0.6990468729599164\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'True')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = random_forest.predict(x_test)\n",
        "\n",
        "print(f\"F1 Score: {f1_score(y_test,y_pred, pos_label= 'positivo')}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test,y_pred)}\")\n",
        "print(f\"Recall Score: {recall_score(y_test,y_pred, pos_label='positivo')}\")\n",
        "print(f\"Precision Score: {precision_score(y_test,y_pred, pos_label='positivo')}\")\n",
        "\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7ONegS7-nd4i"
      },
      "source": [
        "{'n_estimators': 295, 'min_samples_split': 91, 'min_samples_leaf': 26 'max_depth': 98}\n",
        "\n",
        "F1 Score: 0.7140685918192031\n",
        "\n",
        "Accuracy Score: 0.7115333333333334\n",
        "\n",
        "Recall Score: 0.7204\n",
        "\n",
        "Precision Score: 0.7078475042578278"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "19Z3Nfcm8gkx",
        "outputId": "04566c33-add8-43ec-b4b6-25bc097c0398"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=98, min_samples_leaf=26, min_samples_split=91,\n",
              "                       n_estimators=295)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=98, min_samples_leaf=26, min_samples_split=91,\n",
              "                       n_estimators=295)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=98, min_samples_leaf=26, min_samples_split=91,\n",
              "                       n_estimators=295)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " random_forest = RandomForestClassifier(n_estimators=295, min_samples_split=91,min_samples_leaf=26,max_depth=98)\n",
        " random_forest.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "iyNf2QjLIsAY",
        "outputId": "94c1bbbf-9bb0-4a39-b312-2b8187335b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7125041240514681\n",
            "Accuracy Score: 0.7095333333333333\n",
            "Recall Score: 0.7198666666666667\n",
            "Precision Score: 0.7052906596995427\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'True')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = random_forest.predict(x_test)\n",
        "\n",
        "print(f\"F1 Score: {f1_score(y_test,y_pred, pos_label= 'positivo')}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test,y_pred)}\")\n",
        "print(f\"Recall Score: {recall_score(y_test,y_pred, pos_label='positivo')}\")\n",
        "print(f\"Precision Score: {precision_score(y_test,y_pred, pos_label='positivo')}\")\n",
        "\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HSOqCW5omf3u"
      },
      "source": [
        "## Predict de kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "1xIWxCmTmpJe",
        "outputId": "29088696-d927-4544-aeab-9f5fd146910e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0de7b3d5-bbd6-4822-abc2-3b164980e5ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>review_es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>La mayor virtud de esta película es su existen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>No soy un experto cinéfilo, pero pocas veces m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>Si no eres un incondicional del humor estilo T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>No sé qué está pasando, si la gente se deja ll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>Pero cuando amanece,y me quedo solo,siento en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60005</td>\n",
              "      <td>La llegada de Rafa a Euskadi es como ponerse a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60006</td>\n",
              "      <td>El nivel del cine y lo peor la capacidad intel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60007</td>\n",
              "      <td>Es triste ver una película como ésta y escucha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>60008</td>\n",
              "      <td>Puedo entender que Torrente I y II y Lo imposi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>60009</td>\n",
              "      <td>-Ahivalohostia, Txomin, qué montón de gente ri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0de7b3d5-bbd6-4822-abc2-3b164980e5ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0de7b3d5-bbd6-4822-abc2-3b164980e5ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0de7b3d5-bbd6-4822-abc2-3b164980e5ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ID                                          review_es\n",
              "0  60000  La mayor virtud de esta película es su existen...\n",
              "1  60001  No soy un experto cinéfilo, pero pocas veces m...\n",
              "2  60002  Si no eres un incondicional del humor estilo T...\n",
              "3  60003  No sé qué está pasando, si la gente se deja ll...\n",
              "4  60004  Pero cuando amanece,y me quedo solo,siento en ...\n",
              "5  60005  La llegada de Rafa a Euskadi es como ponerse a...\n",
              "6  60006  El nivel del cine y lo peor la capacidad intel...\n",
              "7  60007  Es triste ver una película como ésta y escucha...\n",
              "8  60008  Puedo entender que Torrente I y II y Lo imposi...\n",
              "9  60009  -Ahivalohostia, Txomin, qué montón de gente ri..."
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_criticas_test = pd.read_csv('./test.csv')\n",
        "df_test = df_criticas_test.copy()\n",
        "df_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pHq5JSoAoSVX",
        "outputId": "a1bcdc80-5479-4fe8-e4a1-e4b8096e0085"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
            "<ipython-input-48-0e7876017248>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-233c816d-b242-4405-9d39-d7f73c9a5343\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_palabras</th>\n",
              "      <th>actores</th>\n",
              "      <th>actuación</th>\n",
              "      <th>ahora</th>\n",
              "      <th>al</th>\n",
              "      <th>algo</th>\n",
              "      <th>alguien</th>\n",
              "      <th>algunas</th>\n",
              "      <th>algunos</th>\n",
              "      <th>antes</th>\n",
              "      <th>...</th>\n",
              "      <th>través</th>\n",
              "      <th>uno</th>\n",
              "      <th>veces</th>\n",
              "      <th>ver</th>\n",
              "      <th>vez</th>\n",
              "      <th>vi</th>\n",
              "      <th>vida</th>\n",
              "      <th>visto</th>\n",
              "      <th>ya</th>\n",
              "      <th>él</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>785</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>206</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>319</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>290</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>403</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>358</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>166</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>561</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 160 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-233c816d-b242-4405-9d39-d7f73c9a5343')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-233c816d-b242-4405-9d39-d7f73c9a5343 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-233c816d-b242-4405-9d39-d7f73c9a5343');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   num_palabras  actores  actuación  ahora  al  algo  alguien  algunas  \\\n",
              "0           785        0          0      0   5     0        0        0   \n",
              "1           206        1          0      0   0     1        0        1   \n",
              "2           132        0          0      0   1     0        0        0   \n",
              "3           319        0          0      1   5     1        0        0   \n",
              "4           290        0          0      1   1     0        0        0   \n",
              "5           403        0          0      0   1     0        0        0   \n",
              "6           102        0          0      0   1     0        0        0   \n",
              "7           358        0          0      0   2     0        0        0   \n",
              "8           166        0          0      1   1     0        0        0   \n",
              "9           561        1          0      1   1     0        0        0   \n",
              "\n",
              "   algunos  antes  ...  través  uno  veces  ver  vez  vi  vida  visto  ya  él  \n",
              "0        0      1  ...       0    1      0    2    0   0     1      0   2   1  \n",
              "1        0      0  ...       0    0      1    2    0   0     1      0   0   0  \n",
              "2        1      0  ...       0    0      0    0    1   0     0      0   0   0  \n",
              "3        0      0  ...       0    0      1    0    0   0     0      0   1   0  \n",
              "4        0      0  ...       0    0      0    2    1   0     0      0   0   0  \n",
              "5        0      0  ...       0    1      0    1    0   0     0      0   0   0  \n",
              "6        0      0  ...       0    0      0    0    0   0     0      0   0   0  \n",
              "7        0      0  ...       0    2      0    1    0   0     0      0   0   0  \n",
              "8        0      0  ...       0    0      0    0    0   0     0      0   1   0  \n",
              "9        0      0  ...       0    1      0    2    0   0     0      1   2   0  \n",
              "\n",
              "[10 rows x 160 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['num_palabras'] = df_test['review_es'].str.split().apply(len)\n",
        "\n",
        "vectorizer = CountVectorizer(vocabulary=palabras)\n",
        "matriz_caracteristicas_test = vectorizer.fit_transform(df_test['review_es'])\n",
        "\n",
        "for i, palabra in enumerate(palabras):\n",
        "    df_test[palabra] = matriz_caracteristicas_test.toarray()[:, i]\n",
        "\n",
        "\n",
        "_df_test = df_test.drop(columns='ID',inplace=False)\n",
        "_df_test.drop(columns='review_es',inplace=True)\n",
        "\n",
        "_df_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "G7GnlT-4Kjp8",
        "outputId": "55e8ad2e-57ea-43ba-86c5-5301e44a175a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8dbbe40c-553a-402a-82f0-90485150d40b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60001</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60002</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60003</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60004</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60005</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60006</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60007</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>60008</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>60009</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dbbe40c-553a-402a-82f0-90485150d40b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dbbe40c-553a-402a-82f0-90485150d40b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dbbe40c-553a-402a-82f0-90485150d40b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ID sentimiento\n",
              "0  60000    positivo\n",
              "1  60001    negativo\n",
              "2  60002    negativo\n",
              "3  60003    negativo\n",
              "4  60004    positivo\n",
              "5  60005    negativo\n",
              "6  60006    positivo\n",
              "7  60007    negativo\n",
              "8  60008    negativo\n",
              "9  60009    negativo"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_kaggle_rf = random_forest.predict(_df_test)\n",
        "df_kaggle_rf = pd.DataFrame({'ID': df_test['ID'], 'sentimiento': pred_kaggle_rf})\n",
        "df_kaggle_rf.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDNc8TkFO77r",
        "outputId": "6b2acc2c-d88e-4edc-d739-209401b6e1c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8599"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_kaggle_rf.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LOwqlmzIOsfW"
      },
      "outputs": [],
      "source": [
        "df_kaggle_rf.to_csv('pred_kaggle_ramdom_forest.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Guardo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['RandomForest.sav']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Guardar el arbol\n",
        "import joblib\n",
        "filename = 'RandomForest.sav'\n",
        "joblib.dump(random_forest, filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
